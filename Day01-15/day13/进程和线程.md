### 一、相关概念

今天我们使用的计算机早已进入多CPU或多核时代，而我们使用的操作系统都是支持“多任务”的操作系统，这使得我们**可以同时运行多个程序**，**也可以将一个程序分解为若干个相对独立的子任务**，让多个子任务并发的执行，从而缩短程序的执行时间，同时也让用户获得更好的体验。因此在当下不管是用什么编程语言进行开发，实现让程序同时执行多个任务也就是常说的“`并发编程`”，应该是程序员必备技能之一。

为此，我们需要先讨论两个概念，一个叫`进程`，一个叫`线程`。

**进程就是操作系统中执行的一个程序**，操作系统以进程为单位分配存储空间，每个进程都有自己的地址空间、数据栈以及其他用于跟踪进程执行的辅助数据，操作系统管理所有进程的执行，为它们合理的分配资源。进程可以通过fork或spawn的方式来创建新的进程来执行其他的任务，不过新的进程也有自己独立的内存空间，因此必须通过进程间通信机制（IPC，Inter-Process Communication）来实现数据共享，具体的方式包括管道、信号、套接字、共享内存区等。

**一个进程还可以拥有多个并发的执行线索**，简单的说就是拥有多个可以获得CPU调度的执行单元，**这就是所谓的线程**。由于线程在同一个进程下，它们可以共享相同的上下文，因此相对于进程而言，线程间的信息共享和通信更加容易。当然在单核CPU系统中，真正的并发是不可能的，因为在某个时刻能够获得CPU的只有唯一的一个线程，多个线程共享了CPU的执行时间。使用多线程实现并发编程为程序带来的好处是不言而喻的，最主要的体现在提升程序的性能和改善用户体验，今天我们使用的软件几乎都用到了多线程技术，这一点可以利用系统自带的进程监控工具（如macOS中的“活动监视器”、Windows中的“任务管理器”）来证实。

当然多线程也并不是没有坏处，站在其他进程的角度，多线程的程序对其他程序并不友好，因为它占用了更多的CPU执行时间，导致其他程序无法获得足够的CPU执行时间；另一方面，站在开发者的角度，编写和调试多线程的程序都对开发者有较高的要求，对于初学者来说更加困难。

Python既支持多进程又支持多线程，因此使用Python实现并发编程主要有3种方式：**多进程、多线程、多进程+多线程。**

### 二、多进程

#### Python中启用多进程

Unix和Linux操作系统上提供了`fork()`系统调用来创建进程，调用`fork()`函数的是父进程，创建出的是子进程，子进程是父进程的一个拷贝，但是子进程拥有自己的PID。`fork()`函数非常特殊它会返回两次，父进程中可以通过`fork()`函数的返回值得到子进程的PID，而子进程中的返回值永远都是0。

Python的**os模块**提供了`fork()`函数。由于Windows系统没有`fork()`调用，因此要实现跨平台的多进程编程，可以使用**multiprocessing模块**的`Process`类来创建子进程，而且该模块还提供了更高级的封装，例如批量启动进程的进程池（`Pool`）、用于进程间通信的队列（`Queue`）和管道（`Pipe`）等。

下面用一个下载文件的例子来说明使用多进程和不使用多进程到底有什么差别，先看看下面的代码。

**#普通的单进程下载**：

```python
from time import time, sleep
from random import randint

def download_file(name):
	print('开始下载 %s ...' % name)
	t = randint(1, 10)
	sleep(t)
	print('%s下载完成，用时【%d秒】' % (name, t))

def main():
	start = time()
	download_file('jinpingmei.gif')
	download_file('论语.txt')
	end = time()
	print('全部任务下载完成，总计用时【%.2f秒】' % (end-start))

if __name__ == '__main__':
	main()
```

执行结果：

```shell
开始下载 jinpingmei.gif ...
jinpingmei.gif下载完成，用时【5秒】
开始下载 论语.txt ...
论语.txt下载完成，用时【4秒】
全部任务下载完成，总计用时【9.12秒】
```

从上面的例子可以看出，如果程序中的代码只能按顺序一点点的往下执行，那么即使执行两个毫不相关的下载任务，也需要先等待一个文件下载完成后才能开始下一个下载任务，很显然这并不合理也没有效率。接下来我们使用多进程的方式将两个下载任务放到不同的进程中，代码如下所示。

**#启用多进程进行下载：**

```python
from time import time, sleep
from random import randint
from multiprocessing import Process
from os import getpid, getppid

def download_file(name):
	print('开始下载 %s ...' % name)
	print('本进程id:%s， 父进程id:%s' % (getpid(), getppid()))
	t = randint(1, 10)
	sleep(t)
	print('%s下载完成，用时【%d秒】' % (name, t))

def main():
	start = time()
	p1 = Process(target=download_file, args=('jinpingmei.gif',)) #这个元组的,不能漏
	p1.start() #启动进程
	p2 = Process(target=download_file, args=('论语.txt',))
	p2.start()
	p1.join()
	p2.join()
	end = time()
	print('全部任务下载完成，总计用时【%.2f秒】' % (end-start))

if __name__ == '__main__':
	main()
```

在上面的代码中，我们通过`Process`类创建了进程对象，通过`target`参数我们传入一个函数来表示进程启动后要执行的代码，后面的`args`是一个元组，它代表了传递给函数的参数。`Process`对象的`start`方法用来启动进程，而`join`方法表示等待进程执行结束。运行上面的代码可以明显发现两个下载任务“同时”启动了，而且程序的执行时间将大大缩短，不再是两个任务的时间总和。下面是程序的一次执行结果。

```shell
开始下载 jinpingmei.gif ...
本进程id:5976， 父进程id:3564
jinpingmei.gif下载完成，用时【6秒】
开始下载 论语.txt ...
本进程id:11020， 父进程id:3564
论语.txt下载完成，用时【9秒】
全部任务下载完成，总计用时【9.38秒】
```

我们也可以使用`subprocess模块`中的类和函数来创建和启动子进程，然后通过**管道**来和子进程通信，这些内容我们不在此进行讲解，有兴趣的读者可以自己了解这些知识。

#### 多进程之间的通信

通过上面的案例，我们知道将单进程改造为多进程可以提高程序执行效率。上面的案例中的两个进程执行的**download_file**方法没有任何关联，所以也涉及不到通信的说法。但如果进程之间存在共享资源就需要进行**进程通信**，否则无法保证使用该共享资源时为最新状态。

比如下面这个例子：我们启动两个进程，一个输出Ping，一个输出Pong，两个进程输出的Ping和Pong加起来一共10个。如果进程之间没有实现通信：

```python
from multiprocessing import Process

counter = 0

def pingpong(name):
	global counter
	while counter < 10:
		print('[%d] %s' % (counter, name))
		counter += 1

def main():
	p1 = Process(target=pingpong, args=('ping',))
	p1.start()
	p2 = Process(target=pingpong, args=('pong',))
	p2.start()
	p1.join()
	p2.join()

if __name__ == '__main__':
	main()
```

结果是ping和pong各输出了10次。Why？当我们在程序中创建进程的时候，**子进程复制了父进程及其所有的数据结构**，每个子进程有自己独立的内存空间，这也就意味着两个子进程中各有一个`counter`变量，所以结果也就可想而知了。要解决这个问题比较简单的办法是使用`multiprocessing模块`中的`Queue`类，它是可以被多个进程共享的队列，底层是通过管道和[信号量（semaphore）](https://github.com/jackfrued/Python-100-Days/blob/master/Day01-15)机制来实现的。

使用多进程时，一般使用消息机制实现进程间通信，尽可能避免使用同步原语，例如锁。

消息机制包含： [`Pipe()`](https://docs.python.org/zh-cn/3.7/library/multiprocessing.html?highlight=process#multiprocessing.Pipe) (可以用于在两个进程间传递消息)，以及`队列`(能够在多个生产者和消费者之间通信)。

下面是使用队列实现数据共享的简单例子：

```python
from multiprocessing import Process, Queue

def pingpong(name, q):
	counter = q.get()
	while counter < 10:
		print('[%d] %s' % (counter, name))
		counter += 1
		q.put(counter)
		counter = q.get()
	q.put(counter)

def main():
	q = Queue()
	q.put(0)

	p1 = Process(target=pingpong, args=('ping',q))
	p1.start()
	p2 = Process(target=pingpong, args=('pong',q))
	p2.start()
	p1.join()
	p2.join()

if __name__ == '__main__':
	main()
```

使用`Queue类`来存储共享数据，`put()`方法将数据存储进队列，使用`get()`将数据取出（取不到时进程会默认等待，所以每次取出数据之后又重新将数据存储进去以更新数据），其中一次执行结果如下：

```shell
[0] ping
[1] pong
[2] ping
[3] pong
[4] ping
[5] pong
[6] ping
[7] pong
[8] ping
[9] pong
```

### 三、多线程

#### Python开启多线程

在Python早期的版本中就引入了thread模块（现在名为_thread）来实现多线程编程，然而该模块过于底层，而且很多功能都没有提供，因此目前的多线程开发我们推荐使用`threading模块`，该模块对多线程编程提供了更好的面向对象的封装。我们把刚才下载文件的例子用多线程的方式来实现一遍，有两种实现方法：

##### #使用Thread对象实例实现

```python
from time import time, sleep
from random import randint
from threading import Thread
from os import getpid, getppid

def download_file(name):
	print('开始下载 %s ...' % name)
	print('本进程id:%s， 父进程id:%s' % (getpid(), getppid()))
	t = randint(1, 10)
	sleep(t)
	print('%s下载完成，用时【%d秒】' % (name, t))

def main():
	start = time()
	t1 = Thread(target=download_file, args=('jinpingmei.gif',)) #这个元组的,不能漏
	t1.start() #启动线程
	t2 = Thread(target=download_file, args=('论语.txt',))
	t2.start()
	t1.join()
	t2.join()
	end = time()
	print('全部任务下载完成，总计用时【%.2f秒】' % (end-start))

if __name__ == '__main__':
	main()
```

##### #通过继承Thread类并重写run方法实现

```python
from time import time, sleep
from random import randint
from threading import Thread
from os import getpid, getppid

class DownloadThread(Thread):
	def __init__(self, name):
		super().__init__()
		self.name = name

	def run(self):
		print('开始下载 %s ...' % self.name)
		print('本进程id:%s， 父进程id:%s' % (getpid(), getppid()))
		t = randint(1, 10)
		sleep(t)
		print('%s下载完成，用时【%d秒】' % (self.name, t))

def main():
	start = time()
	d1 = DownloadThread('jinpingmei.gif')
	d1.start()
	d2 = DownloadThread('论语.pdf')
	d2.start()
	d1.join()
	d2.join()
	end = time()
	print('全部任务下载完成，总计用时【%.2f秒】' % (end-start))

if __name__ == '__main__':
	main()
```

#### 多线程之间的共享数据

因为**多个线程可以共享进程的内存空间**，因此要实现多个线程间的通信相对简单，大家能想到的最直接的办法就是设置一个全局变量，多个线程共享这个全局变量即可。但是当多个线程共享同一个变量（我们通常称之为“资源”）的时候，很有可能产生不可控的结果从而导致程序失效甚至崩溃。如果一个资源被多个线程竞争使用，那么我们通常称之为“**临界资源**”，对“临界资源”的访问需要加上保护，否则资源会处于“混乱”的状态。下面的例子演示了100个线程向同一个银行账户转账（转入1元钱）的场景，在这个例子中，银行账户就是一个临界资源，在没有保护的情况下我们很有可能会得到错误的结果。

```python
from threading import Thread
from time import sleep

class Account():
	def __init__(self):
		self._balance = 0

	@property
	def balance(self):
		return self._balance

	#转入
	def add(self, money):
		new_balance = self._balance + money
		sleep(0.01) #模拟转账的处理过程，否则看不出效果
		self._balance = new_balance

class addMoneyThread(Thread):
	def __init__(self, account, money=0):
		super().__init__()
		self.account = account
		self.money = money
	
	def run(self):
		self.account.add(self.money)

def main():
	#100线程模拟100人向同一账户同时转账
	account = Account()
	threadlist = []
	for _ in range(0, 100):
		t = addMoneyThread(account, 1)
		threadlist.append(t)
		t.start()
	for t in threadlist:
		t.join()
	#查看账户余额
	print('账户余额：%.2f' % account.balance)

if __name__ == '__main__':
	main()
```

执行会比100小很多，这是因为在**sleep(0.01)**时，多个线程同时进行了**new_balance = self._balance + money**的计算，像金额balance这样的边界资源在被多个线程同时执行并修改时就会出现混乱。

所以，对于多线程共享数据的问题，我们一般是加上一把`锁`，来对正在处理的临界资源进行锁定，即不让其他线程对其进行修改。这样，这个临界资源就能保证在同一时间只被同一线程变更，也就不会发生混乱。

我们使用`Threading模块`中的`Lock`即可实现：

```python 
from threading import Thread, Lock
from time import sleep

class Account():
	def __init__(self, lock):
		self._balance = 0
		self._lock = lock

	@property
	def balance(self):
		return self._balance

	#转入
	def add(self, money):
		self._lock.acquire() #请求加锁
		try:
			new_balance = self._balance + money
			sleep(0.01) #模拟转账的处理过程，否则看不出效果
			self._balance = new_balance
		finally:
			self._lock.release() #释放锁，释放资源

class addMoneyThread(Thread):
	def __init__(self, account, money=0):
		super().__init__()
		self.account = account
		self.money = money
	
	def run(self):
		self.account.add(self.money)

def main():
	#100线程模拟100人向同一账户同时转账
	lock = Lock()
	account = Account(lock)
	
	threadlist = []
	for _ in range(0, 100):
		t = addMoneyThread(account, 1)
		threadlist.append(t)
		t.start()
	for t in threadlist:
		t.join()
	#查看账户余额
	print('账户余额：%.2f' % account.balance)

if __name__ == '__main__':
	main()
```

### 四、多进程还是多线程

无论是多进程还是多线程，只要数量一多，效率肯定上不去，为什么呢？我们打个比方，假设你不幸正在准备中考，每天晚上需要做语文、数学、英语、物理、化学这5科的作业，每项作业耗时1小时。如果你先花1小时做语文作业，做完了，再花1小时做数学作业，这样，依次全部做完，一共花5小时，这种方式称为单任务模型。如果你打算切换到多任务模型，可以先做1分钟语文，再切换到数学作业，做1分钟，再切换到英语，以此类推，只要切换速度足够快，这种方式就和单核CPU执行多任务是一样的了，以旁观者的角度来看，你就正在同时写5科作业。

但是，切换作业是有代价的，比如从语文切到数学，要先收拾桌子上的语文书本、钢笔（这叫保存现场），然后，打开数学课本、找出圆规直尺（这叫准备新环境），才能开始做数学作业。操作系统在切换进程或者线程时也是一样的，它需要先保存当前执行的现场环境（CPU寄存器状态、内存页等），然后，把新任务的执行环境准备好（恢复上次的寄存器状态，切换内存页等），才能开始执行。这个切换过程虽然很快，但是也需要耗费时间。如果有几千个任务同时进行，操作系统可能就主要忙着切换任务，根本没有多少时间去执行任务了，这种情况最常见的就是硬盘狂响，点窗口无反应，系统处于假死状态。所以，多任务一旦多到一个限度，反而会使得系统性能急剧下降，最终导致所有任务都做不好。

是否采用多任务的第二个考虑是任务的类型，可以把任务分为计算密集型和I/O密集型。计算密集型任务的特点是要进行大量的计算，消耗CPU资源，比如对视频进行编码解码或者格式转换等等，这种任务全靠CPU的运算能力，虽然也可以用多任务完成，但是任务越多，花在任务切换的时间就越多，CPU执行任务的效率就越低。计算密集型任务由于主要消耗CPU资源，这类任务用Python这样的脚本语言去执行效率通常很低，最能胜任这类任务的是C语言，我们之前提到了Python中有嵌入C/C++代码的机制。

除了计算密集型任务，其他的涉及到网络、存储介质I/O的任务都可以视为I/O密集型任务，这类任务的特点是CPU消耗很少，任务的大部分时间都在等待I/O操作完成（因为I/O的速度远远低于CPU和内存的速度）。对于I/O密集型任务，如果启动多任务，就可以减少I/O等待时间从而让CPU高效率的运转。有一大类的任务都属于I/O密集型任务，这其中包括了我们很快会涉及到的网络应用和Web应用。

### 五、多线程+异步I/O

现代操作系统对I/O操作的改进中最为重要的就是支持异步I/O。如果充分利用操作系统提供的异步I/O支持，就可以用单进程单线程模型来执行多任务，这种全新的模型称为**事件驱动模型**。Nginx就是支持异步I/O的Web服务器，它在单核CPU上采用单进程模型就可以高效地支持多任务。在多核CPU上，可以运行多个进程（数量与CPU核心数相同），充分利用多核CPU。用Node.js开发的服务器端程序也使用了这种工作模式，这也是当下实现多任务编程的一种趋势。

在Python语言中，单线程+异步I/O的编程模型称为`协程`，有了协程的支持，就可以基于事件驱动编写高效的多任务程序。协程最大的优势就是极高的执行效率，因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销。协程的第二个优势就是不需要多线程的锁机制，因为只有一个线程，也不存在同时写变量冲突，在协程中控制共享资源不用加锁，只需要判断状态就好了，所以执行效率比多线程高很多。如果想要充分利用CPU的多核特性，最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。关于这方面的内容，我稍后会做一个专题来进行讲解。

### 六、练习

#### 例子1：将耗时间的任务放到线程中以获得更好的用户体验。

下面是用time.sleep模拟下载等待的例子，当我们点击全部下载时是逐一下载，需要等待时间，用户体验较差，请使用多线程解决这个问题。

```python
import tkinter
from time import sleep, time
from random import randint

def download_file(name):
	t = randint(1, 3)
	sleep(t)
	return t

def main():
	names = ['jinpingmei.gif', 'lunyu.txt', 'daxue.pdf'] #要下载的文件

	def download_all():
		start = time()
		label['text'] = ''
		for name in names:
			t = download_file(name)
			msg = '\n%s下载完成，用时【%d】秒' % (name, t)
			label['text'] += msg
		end = time()
		msg = '\n全部下载完成，总共用时【%.2f】秒' % (end-start)
		label['text'] += msg
		btn['text'] = 'Download Again'

	#顶层窗口
	tk = tkinter.Tk()
	tk.geometry('240x160')
	tk.title('download')
	#GUI
	frame = tkinter.Frame(tk)
	frame.pack(side='bottom')
	#按钮
	btn = tkinter.Button(frame)
	btn['text'] = 'Download All'
	btn['command'] = download_all
	btn.pack(side='bottom')
	#显示标签
	label = tkinter.Label(tk, fg='red')
	label['text'] = 'download lists:\n'
	label['text'] += '\n'.join(names)
	label.pack(expand=1)

	#开启主事件循环
	tkinter.mainloop()

if __name__ == '__main__':
	main()
```

[参考代码]()

#### 例子2：使用多进程对复杂任务进行“分而治之”

我们来完成1~100000000求和的计算密集型任务，这个问题本身非常简单，有点循环的知识就能解决，代码如下所示。

```python
from time import time

def main():
	total = 0

	maxnum = 100000000
	start_time = time()
	for x in range(1, maxnum+1):
		total += x
	print(total)
	end_time = time()
	print('Execution time: %.3fs' % (end_time - start_time))

if __name__ == '__main__':
	main()
```

请分别使用多进程和多线程来提高计算效率：

[参考：多进程]()

[参考：多线程]()

